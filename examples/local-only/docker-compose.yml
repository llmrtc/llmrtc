version: '3.8'

# Local AI services for LLMRTC
# Run: docker-compose up -d

services:
  # Faster-Whisper for Speech-to-Text
  faster-whisper:
    image: fedirz/faster-whisper-server:latest-cpu
    ports:
      - "8000:8000"
    environment:
      - WHISPER_MODEL=base.en
      - WHISPER_DEVICE=cpu
    restart: unless-stopped

  # Piper for Text-to-Speech
  piper:
    image: rhasspy/wyoming-piper:latest
    ports:
      - "5000:10200"
    command: --voice en_US-lessac-medium
    restart: unless-stopped

# Note: Ollama should be installed natively for best performance
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Run: ollama serve
# Pull model: ollama pull llama3.2
